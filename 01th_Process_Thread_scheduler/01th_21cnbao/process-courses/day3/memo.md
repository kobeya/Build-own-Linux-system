上半部：进程类型与CPU处理的情型
1，吞吐与响应。
	吞吐：CPU几乎在做有用工
	响应：CPU会花很多时间在上下文切换，当然上下文切换速度其实也很快，但是上下文
	切换的后果会导致出现各种cache miss，系统的性能就会下降。

2，I/O bound与 CPU bound。
	I/O bound类型的进程，对CPU的利用率低，进程的运行效率主要受限与I/O速度。
	举个例子：DMA操作
	
	time *  -|--------------------------------------------------------
		^					^
		|					|
	DMA创建+初始化指令			DMA操作，I/O处理
	
	分析：假设DMA创建+初始化指令，这部分是CPU在做的时候，花了1ms；
	DMA的操作，花了100ms，那么整个耗时在101ms。
	      如果，我们让CPU的能力缩减一半，此时，CPU创建DMA流程需要2ms；
	DMA操作，依然是100ms，那么整个耗时在102ms。

	可以看得出来，CPU的能力，并没有影响到非常大的进程效率。
	因此，我们的ARM架构，都是采用big.LITTLE的模型，大小核。
	这样，我们的手机厂商，可以通过4个big+4个LITTLE到达到：4.X的大核功耗，获取7.X的性能！！！

		
3，因为我们的进程分为I/O bound and CPU bound，这就引出了我们的schedule,我们需要足够好的schedule策略。



下半部：调度器schedule

一, 早期2.6的调度器，优先级数组+Bitmaps
	理解优先级数字：
	Linux的RT调度策略和normal的调度策略在算法上，是有差异的。
	
	1、RT
	
	RT的SCHED_FIFO和SCHED_RR采用的是
	一个Bitmap：
	1bit,对应一个优先级，这个优先级里面有一个list of all runnable tasks,里面可能有ready的进程。
	schedul() -> sched_find_first_set() -> bit(process)
	调度器每次都从0bit开始遍历这个数组，找到第一个有进程ready的bit，然后调度这个bit的优先级对应
	的进程。
	所以，在内核里面，优先级的数字，越小，说明优先级越高。


	可以认为每个bit里面都有一个队列，但是队列里面不一定有等待的进程	
		|
	0 1 2 3 4 5 6 7 8 9 . . .	 . . . 139	
	口口口口口口口口口口口口口口... ...口口口	
	——————————————————————————————————————————————————————

	但是，从用户态的API里面，则是数字越大，优先级越高。(也就是我们在输入命令或者工具或者在
	代码用户API在设置的数值)
	struct sched_param the_priority;
	the_priority.sched_priority = 50;
	pthread_setschedparam(pthread_self(), SCHED_FIFO & the_priority);
	

	引出一个算式，用户API的优先级数值与内核优先级数值的转换关系：
			内核优先级数值 = 99 - 用户API优先级数值
	———————————————————————————————————————————————————————

	但是，从top命令的视角，又与两者不同：
	对于RT进程，
			top的视角 PR = （-1）-（用户视角）		
	也可以看出来，top视角与内核类似，数值越小，优先级越大！

	而且，这里还有一个特例，就是用户的99，对应内核Bitmap中的0优先级，
	top这个时候，显示为rt，
	这说明，只有最高优先级的RT进程，才在top中显示为rt！！！
	———————————————————————————————————————————————————————
	工具：chrt
	sudo chrt -f *(用户API优先级数值) ./a.out(修改优先级的当前进程) 
	-f是把task_struct设置为SCHED_FIFO， -a是进程中所有的线程 -p 期望优先级
	很明显，我们应该知道内核提供了API实现这些功能，也就是在coding的时候，我们可以动态
	调整这些值！	

	2、normal

	我们更关注它的nice值：
	-20~19之间。

	nice值越小，优先级越高，权重越大，在CFS红黑树的左边的机会越大。
	实际上，红黑树最左边的值，缓存在一个rb_left的变量中，可以加快调度速度。

	sudo nice -n * ./a.out

	top视角看到的优先级:
	20 + nice值
	
	————————————————————————————————————————————————————————
	总结:
	① 在优先级的世界，总共有内核、top、用户API三个视角
	② 在优先级的世界里，我们还可以设置一个nice来表示进程的运行权重
	这里有个问题？ 那么优先级与 nice值的关系现在到底咋样？
	简单查阅了一下，暂时理解为：nice值影响进程的优先级，影响cpu时间分配的权重。
	nice值，参与修正优先级。这样可以看到换算的算式：
	优先级(new) = 优先级(old) + nice
	
	


	因此：
	① 整个Linux内核空间，把划分为0~139之间
	② 数字越小，优先级越高
	③ 0~99对应的是实时RT进程
		


 
	最高优先级									   最低优先级	
	0							  99/100			  139
	|-----------------------------------------------------------|-------------------------------|
	|							    |
	|------------------------> RT实时进程<----------------------|----------->normal进程<--------|

								   -20                             19	
								    |------------>nice 值<----------|		




			---SCHED_FIFO：优先级高一直执行，直到睡眠主动让出CPU，同等优先级，先来做跑
	RT的调度策略是:	|
			---SCHED_RR：优先级高一直运行，直到睡眠主动放弃CPU，同等优先级轮流跑

	存在问题：如果RT扑街，自己把自己搞死在执行上，也就是出了bug，死循环的话，那么非RT进程
			就一点机会都没有了！

	







			---不会有绝对的优势，不同优先级轮流执行
			|		---获取更多的时间片
	非RT的调度策略：---nice的作用   |
			|		---在睡眠唤醒的时候，优先执行，但是执行后，也是会与低优先级的
					轮流执行
			---根据睡眠的情况，动态奖励，惩罚---这个奖励惩罚的作用，
			其实已经开始对I/O、CPU不同消耗性的进程，进行一个CPU处理的迁移，
			在I/O消耗型与CPU消耗型的进程同时出现的时候，I/O消耗型能够竞争过CPU消耗型。

			不过，这都不够好，还是会存在问题如下：
			（摘自《Linux内核设计与实现》,后面有时间，还会增加其他书籍的描述，
			我有段时间在不同的书籍看到不同的解释，现在想知道最接近真实的解释！）
			① 如果nice映射到时间片，就必然需要将nice值对应到处理器的绝对时间，
				比如一个nice值，代表5ms的时间片，
				这样就会出现进程切换的时候，无法最优化。
				比如：
				两个进程，一个nice为0的进程100ms的时间片，一个nice值为19的进程
				5ms时间片，那么他们会在105ms内做一次切换；
				如果两个优先级相等的进程，他们会在持续的5ms时间间隔不断的切换
				获取相等的时间，这个时候，进程切换其实是不够合理的！
				简单来说，早期nice来决定执行时间长短的后果，需要一个绝对值来
				限制进程切换(5ms)，这就导致可能出现切换不合理。

			② nice值映射到的时间片不合理，两个进程之间的时间片分配比例，
				极大的取决与两个进程nice的初始值。
				比如：
				他们会在持续的5ms时间间隔不断的切换
				获取相等的时间，这个时候，进程切换其实是不够合理的！
				比如：
				A进程nice初值为0，对应的时间片为100ms
				B进程nice初值为1，对应的时间片为95ms
				那么他们的时间比例为100:95

				C进程nice初始化值为18，时间片10ms		
				D进程nice初始化值为19，时间片为5ms
				那么他们的时间比例为 2:1

			③ 第一个问题，描述到一个绝对时间片，这个绝对时间片，实际上存在限制条件：
				一是，这个最小时间片必然是定时器的节拍影响，10ms~1ms的稳定差距	
				二是，绝对值，也限制了这个时间片的精度
				---这本书，还强调，这是引入CFS的唯一原因！！！
flag：2020年07月29日17:12:31



				
	
			等等，其实我们可以采用某些特定的手段去处理这些问题，但是都其实根本问题
			解决：分配绝对的时间片，引发的固定的切换频率，会给公平性造成变数！！！

			CFS悠然出现，将固定的切换频率置于不断变动之中，确保恒定的公平性。



 
	



二， 后期Linux，可以理解为现在的Linux
	
	
	1，针对早期RT调度策略存在的问题：如果RT拥有至高无上的优先权，获得CPU并且一直执行，出现bug，
			死循环，那么非RT就一点机会都没有了。
						 ---/proc/sys/kernel/sched_rt_period_us，默认100000
	优化：产出一个patch，限制RT进程的运行时间
					 	 ---/proc/sys/kernel/sched_rt_runtime_us，默认95000
		
	作用就是：不管是SCHED_FIFO还是SCHED_RR策略的RT进程，在一个100000ms(1s)的周期里面，
			RT进程最多，只能执行95000ms(0.95s)！



	2，针对normal进程，也就是非RT进程原来的nice调度策略的问题，简单的说，就是时间片会映射到一个
	绝对时间，这样就导致进程切换的时候，需要采用固定的频率，存在非常大的隐患。

	优化：CFS调度算法。
	（追求虚拟时间，完全相等，所有进程均分CPU，当然这是不现实的！）
	
		2.1 这里引入《Linux内核设计与实现》的描述——>CFS是如何实现的。
			① 时间记账
			可以参考这个帖子：https://www.cnblogs.com/linhaostudy/p/9946814.html
			CFS不再有时间片的概念，但是仍然需要维护进程的时间记账。
			使用实体结构 struct_sched_entity 来追踪进程运行记账：

				task_struct {
					se(PCB的成员变量)
				};	|
					|
					|	
					^
				struct sched_entity {
					struct load_weight	load;
					struct rb_node		run_node;
					.
					.
					.
					u64			vruntime;
					u64			sum_exec_runtime;//真实运行时间
					.
					.
					.
				};
					|
					|
					|
					v
				update_curr()实现记账功能
				{
					调用几个函数，分别做以下事情：
					首先计算进程当前时间与上次启动时间的差值
					通过负荷权重和当前时间模拟出进程的虚拟运行时钟
					重新设置cfs的min_vruntime保持其单调性
				}

				这里注意：
				update_curr这个函数，是系统定时器周期性调用，所以，无论进程
				在运行还是在阻塞，vruntime都可以准确的测量给定进程的运行时间。
				优先级越高，权重越大，vruntime行走的就越慢，那么在红黑树种
				向右移动的速度就越慢，cpu调度该进程的几率就越大。
	
			【这里有个非常重要的变量vruntime】

			解剖vruntime：
			A ns为单位，与定时器节拍无关，记录一个进程到底运行了多长时间和还剩多长时间
			B 虚拟运行时间，是通过进程实际运行时间+进程的权重计算出来的。
				在宋宝华的视频里提到一句：
						物理时间
				vruntime =  ———————————————— X 1024
						权    重
	
 
			② 进程选择
			首先我们知道，CFS使用红黑树来组织可运行队列的，选择最左侧的叶子节点，
			也就是vruntime的最小值。

			③ 调度器入口
			入口点函数：schedule();
			主要做的事情：
			A 找到最高优先级的调度类（rt_sched_class、fair_sched_class、idle_sched_clas）
			怎么找？
			代码里有个小技巧，把当前所有进程数量与CFS类中的进程数量做比较，
			如果相等，那么就直接在CFS类中找到下一个运行的进程。
			否则，在再去找其他优先级的类。
			注意，这里不会返回非0,因为，就算没有其他进程可以调度，依然会执行idle 0号进程


			④ 睡眠和唤醒

			参考day1中的读写等待队列吧，这里因为时间问题，不深入了。

		2.2 宋大侠的视频解读
				物理执行时间，也就是进程真实运行时间			       	
		vruntime = ———————————————————————————————————————————— X 1024
					权		重
		解释：schedule() -> sched_class_high -> CFS ->当前vruntime最小的task_struct被调用，
			当进程随着时间运行，物理执行时间增加，vruntime的值变大，开始按照红黑树
			往右边滚动。右边也就开始往左边滚动，达到调度目的。

			同样，我们可以看出来，越是执行时间短的进程，vruntime越小，越有可能得到
			CPU资源！


		知识点：
			A 每个进程可能有多个线程，每个线程的权重vruntime可能都不一样，
				甚至调度类都不一样

			B 红黑树，几乎可以说，已经没有了优先级+nice+时间片这些概念了！ 


			C 工具chrt与renice
			
			举例子：
			chrt -f -a -p 50 10594
			-f,表示把进程设置为SCHED_FIFO RT进程
			-a,表示把进程中所有的线程都统一起来
			-p,用户API的优先级数值(请注意，在top视角跟内核视角的转换)
			

			这个工具，就是把一个normal进程，设置为RT进程！
[WARNING]		有人问到，如果同时存在FIFO RR，那么怎么调度？
			宋大侠回复：不存在这个情况，还有其实实际中很少用到RT

			renice -n 5 -g 9415
			-n,用户API视角的nice值
			-g,全局

			这个工具，就是把正在执行的进程，修改nice值。
[BUG]			在测试这个工具的时候，居然没有任何效果！！！
		


			nice -n 5 ./a.out

			这个工具，在进程启动的时候，静态分配nice值。

			
			D 综合理解一下task_struct 进程、线程与调度：
			不管是进程还是线程，都用task_struct来描述，
			调度，是针对task_struct的
			进程有可能有多个线程在执行，
			但是线程，就一个task_struct,所以，我们可以认为：
			线程是调度单位，进程是资源封装的单位！！！
		
		
			E 默认nice值为0  权重1024～

			F 提到一个LMbench工具来观察cache miss














