【一、导读】
	因为我本人距离camera项目的产出已经有不短的时间了，所以曾经觉得很清晰的知识回忆起来已经模糊，
	为了后续深入camera，只能通过本文收集各方面的资料，先做一个系统上的认知，可能会有点零散，但
	尽量满足理解整个camera的基本原理。

	再次重申，我本人是无意往camera单方向发展的，虽然我接过几个项目，调过几款camera，但按照我的
	理解，是远达不到专业的camera tuning工程师的水平，里面涉及的算法也只是浅尝辄止，bing up罢了。

【二、理论基础与工作原理】

	1，camera认知
		1）摄像头模组CCM，camera compact Module，摄像头微型模组

		2）CCM内部硬件结构

				镜头片	—————————
					|	|
				镜头	|	|
				————————————————————————————
				镜座	—————————
			IRFilter	～～～～～
			
			CMOS感应器	-----------
				电阻口		      口电容
			——————————————————————————————————————————————PCB、FPC
		
	2，工作原理
		1）光线通过镜头Lens，进入摄像头内部
		2）经过IR Filter过滤红外光
		3）过滤红外光的光信号到达CMOS sensor传感器(按照材质也可能是CCD电荷耦合)
		4）CMOS传感器将光信号--->电信号
		5）电信号经过内部的ADC电路--->数字信号
		6）数字信号传输到DSP加工处理，转换成RGB、YUV等格式输出

		（如果没有DSP，则以DVP的方式传递到基带芯片baseband，也就是外挂DSP
		此时数据格式为RAW data）

	3，镜头Lens
		镜头是相机的灵魂，单反中一个镜头上万是很随意的事。镜头对成像有很重要的作用，
		相当于人眼中的晶状体，利用透镜的折射原理，景物光线透过镜头在聚焦平面上形成清晰的像，
		然后通过感光材料CMOS或CCD记录影像，并通过电路转换为电信号。镜头产业有比较高的技术
		门槛，国外主要集中在日本、韩国，国内主要是在台湾，
		业内比较知名的如：富士精机、柯尼卡美能达、大力光、Enplas等。
    		Lens一般由几片透镜组成透镜结构，按材质可分为塑胶透镜(plastic)或玻璃透镜(glass)，
		玻璃镜片比树脂镜片贵。塑胶透镜其实是树脂镜片，透光率和感光性等光学指标比不上镀膜
		镜片。
		通常摄像头采用的镜头结构有：1P、2P、1G1P、1G2P、2G2P、2G3P、4G、5G等。
		透镜越多，成本越高，相对成像效果会更出色（个人理解是光线更均匀、更细致；
		对光线的选通更丰富；成像畸变更小，但是会导致镜头变长，光通量变小）。

	4，IR Filter红外滤光片
		人眼看不到红外光，但是感光芯片可以感应，为了让景象贴近人眼效果，滤掉红外光线。

	5，传感器sensor
		1）感光，并负责光信号->电信号，再经过内部AD->数字信号
		2）像素，每一个pixel像素只能感光R、G、B三种原色中的一种，也就是单色光。
			所以我们常说500万像素、1000万像素，指的就是感光sensor拥有的感光点。
			每个感光点，感应一种单色光，这些最原始的感光数据我们称为RAW data，
			所以，如果我们遇到成像有槽点、大小不一致，可以直接拦截RAM data分析，是否
			感光IC出了问题。
		3）RAW data，经过sensor模组自带的ISP部分(Image Sensor Processor)处理还原出三原色。
			如果一个像素点感应为R值，那么ISP会根据该感光点周围的G、B的值，通过插值和
			特效处理等，计算出该R点的G、B的值，这样该点的RGB的混合色彩就被还原了。

		4）sensor材质
			a	CCD，电荷耦合，Charge Coupled Device
				使用一种高感光度的半导体材料制成，将光线->电荷->AD->电信号
				以日本厂商为主导，全球90%市场被日本垄断，索尼、松下、夏普等

			b	CMOS，互补性氧化金属半导体，Complememtary Metal-Oxide Semiconductor
				主要利用硅、锗做出的半导体，N- P+互补效应产生电流
				以美国、韩国、中国台湾为主导，美国的OmnVison、Agilent、Micron，
				中国台湾的锐像、原相、泰视等，韩国的三星、现代。

		5）DSP，图像处理芯片
			DSP包括两部分， ISP(Image Signal Processor)和JPEG，图像解码器
			a	ISP将RAW数据做AWB、color matrix、lens shading、gamma、sharpness、AE、
				de-noise处理，最终输出为YUV或者RGB格式的数据。
			b	JPEG图像解码器，有软硬件之分。
		备注：DSP中的ISP是图像信号处理器，前面描述的RAW data还原ISP是图像传感处理器，两码事。

	6，ISP、DSP和baseband芯片的区别和联系
		1）基带芯片，相当于一个协处理器，也包含自己使用的dsp、flash等单元。
			主要作用是合成要发送的数据为基带码，或者解码接受到的基带码为音频信号等。

		2）ISP，图像处理器，
			a	ACE，自动曝光控制
			b	AGC，自动增益控制
			c	AWB，自动白平衡
					原理是利用色温曲线，调节三基色的比例来达到彩色的平衡。
			d	色彩校正
			e	Gamma，伽马校正
			f	祛除坏点
			g	自动黑级别
			h	自动白级别
			等等算法

		3）DSP，我们可以认为ISP是一种针对图像信号处理的dsp，都是对RAW数据处理。
		如果ISP表示图像信号处理，那么它就属于DSP的一部分
		如果ISP表示图像传感器处理器，那么它就属于sensor模块的一部分，又DSP做处理。
			

	7,3D模组
		多台摄像头拍摄图像，然后组合。

	8，sensor输出的图像格式
		1）YUV，luma(Y) + chroma(UV)，亮度+色度
			一般情况下，sensor支持YUV422格式，也就是Y-U-Y-V词序输出数据。
		2）RGB，比如RGB565,5bit R + 6bitG + 5bit B，G多1bit，是因为人眼对绿色敏感
		
		3）RAW RGB，每个像素只采集一种单色，对应一个彩色滤光片，滤光片按Bayer pattern分布，
			也就是拜耳模板分布，将每一个像素采集到的原始色彩直接输出为RAW RGB data。
		4）JPEG，有些低分辨率的sensor，自带JPEG engine，可以直接输出压缩为jpg的数据

	9，YUV格式与RGB格式的比较
		1）YUV输出数据的亮度信号没有任何损失，而色度信号偏差，人眼又不是特别敏感
		2）RGB565，R5G3 G3B5输出格式，会丢失很多原始信息

		综上，YUV图像质量和稳定性都比RGB565要好的多
		因此，一般只有低端的基带芯片才会输出RGB565格式。

	10，RAW与jpeg比较
		明显，RAW是图像的原始数据，像素采光后，直接记录，然后isp做一些算法还原
		jpeg就是做了处理，比如压缩等等，已经丢失了部分数据。

	
	11，输出、输入接口
		1）串行接口，RS232、422，传输速率慢，115KB/s
		2）并行接口，PP，1Mbit/s
		3）红外接口，IrDA，115KB/s，一般笔记本使用这种接口
		4）通用串行USB，USB1.1,12Mbit/s、USB2.0,480Mbit/s
		5）IEEE1394火线接口，ilink，100M～400Mbit/s

	12，camera时钟域，每个摄像头都有三个时钟域
		1）系统总线时钟域
		2）摄像头像素时钟域PCLK
		3）内部始终存在的时钟域MCLK，主控中的控制器提供同步时钟
		系统总线时钟域必须高于PCLK，MCLK必须固定频率工作，比如PLL时钟。

	13，工作启动
		给摄像头时钟，并复位摄像头，摄像头驱动需要完成三步启动
		1）摄像头上电、时钟
		2）i2c保证摄像头初始化，并提供给主控配置或者读取摄像头寄存器通道，
			CPU通过i2c接口，配置信息控制camera工作。
		3）摄像头工作后传回数据到主控

扩展阅读：
1）AWB算法，https://blog.csdn.net/wzwxiaozheng/article/details/38434391
2）基础原理总结贴，里面还包含它自己的总计贴
	https://www.cnblogs.com/fjutacm/p/220631977df995512d136e4dbd411951.html
3) 3A算法理解，https://blog.csdn.net/cheng401733277/article/details/73413368
4）知乎上一个camera tuning的主页，https://www.zhihu.com/people/jiao-tao-52/posts
5）camera与3A模式代码分析，https://www.jianshu.com/p/10ffe3f7018a







































