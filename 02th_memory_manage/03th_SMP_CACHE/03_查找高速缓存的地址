【索引】
	02章节中已经描述了CPU通过地址查找cache是否命中。
	而且我们知道现在的CPU均包含MMU将VA与PA的转换，在应用角度看，CPU访问的所有地址都应该是虚拟地址
	但是cache的硬件设计真的就是物理地址吗？

	这就是我这章的主题：
			
			cache的访问地址
			～～～～～～～

	以下讨论的内容，均默认系统拥有MMU

	1，首先要理解地址
		1）虚拟地址，每个进程拥有自己独立的地址空间，独立的页表，页表里面管理着自己的
		   VA-PA的映射关系。
		2）虚拟地址经过MMU翻译（TLB），其实也就是页表查找后得到物理地址
		
		以上的情况需要思考以下问题
		1）别名，不同进程的不同虚拟地址映射到同一个物理地址，tag
		2）歧义，不同进程的相同的虚拟地址映射到不同的物理地址，index
		3）性能，不管是MMU还是TLB还是flush cache等都需要损耗性能
		
		备注，别名和歧义，其实可以简单的理解为
		从物理地址出发，如果映射到不同的虚拟地址，虚拟地址对应用户空间，用户空间就发生歧义；
				如果不同PA映射到相同的VA，用户空间看到都是一个名字的效果，就发生别名


	2，如果我们cache硬件上设计成VIVT（Virtually Index Virtually Tagged）
		明显，可能出现歧义和别名的问题
		如果此刻如是想在这种情况下解决歧义和别名的问题，那么就需要在进程切换的时候
		先写回前一个进程的cache，然后再flush cache清空cache，
		这样就会出现非常大的性能损耗而且影响进程切换后的执行效率。


	3，如果我们cache硬件上设计成PIPT
		当然可以完全解决上面的问题，
		到这里，一般情况下，我们可以直接回复最初的问题，cache的设计就是物理寻址。
		包括我们现在的处理器大部分都是采用PIPT，Linux内核中对PIPT cache的管理函数都是空函数
		但是，这样其实还是有一些可以优化的问题：
		性能
		没错，PIPT的要求是每次寻址都先经过TLB或者MMU翻译成PA
		软件上几乎不需要维护，但是硬件的设计就要复杂很多，而且对性能也有一点损耗。

	4，但是系统其实还未我们提供更加优化的选择VIPT
		如果多路组相连高速缓存的一路的大小小于等于4KB，一般硬件采用VIPT方式，
		因为这样相当于PIPT。
		如果一路大小大于4KB，一般采用PIPT方式，也不排除VIPT方式，这就需要系统采用什么策略

		
总结：如果有人跟你谈论，cache的寻址方式是物理寻址，也没什么问题，因为现在的cpu基本都采用这种模式，
	但是你脑子里应该清醒，如果公司业务需求，针对性想做一些优化，那么你就要仔细核实一下cache的
	硬件设计，一路的大小是多少，是否可以采用VIPT的策略了。
